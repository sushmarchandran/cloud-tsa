# Get Started

Run the CloudTSA demos in your Kubernetes environment.

# Table of Contents
1. [Background](#background)
2. [Requirements](#requirements)
3. [Initialize](#initialization)
4. [Run the demos](#run)
    - [Demo 1: Predictively monitor gradual drifts in latency](#predict)
    - [Demo 2: Detect abrupt increases in latency](#abruptlatency)
    - [Demo 3: Detect abrupt increases in error](#abrupterror)
    - [Demo 4: Detect peaks in load](#peak)

<a name="background"></a>
## Background
These demos illustrate the various time series detection capabilities of CloudTSA
and how they can be combined with an application's performance metrics in Prometheus in order to generate real-time insights. The demos utilize a sample application based on [Istio](https://istio.io), a micro services mesh for distributed [Kubernetes](https://kubernetes.io)
applications. The sample application consists of a collection of services which
are queried by a load generator. The behavior of these services are modified by the different demos for illustration purposes. While Istio and Kubernetes are required for running the demos, CloudTSA can be used with any application whose metrics are available in a Prometheus database.

<a name="requirements"></a>
## Requirements

* Installed Kubernetes 1.9 or later
* Installed kubectl
* Have a kubeconfig file (default location is `~/.kube/config`)
* Installed Istio 1.0.0 or later
  + Ensure your Istio is installed with Prometheus and Grafana addons enabled. Prometheus is enabled by default. To enable Grafana use the `grafana.enabled` flag in the Istio helm installer as follows.
    - `
    helm template install/kubernetes/helm/istio --name istio --set grafana.enabled=true --namespace istio-system > $HOME/istio.yaml
  `
* Installed istioctl
* Downloaded iter8 (you can do so using `git clone git@github.ibm.com:istio-research/iter8-final.git`)
* Python 3.6 or later
* Installed python packages `requests`, `numpy` and `PyYAML` (you can do so by running `pip install requests numpy` and by following the instructions on the [PyYAML](https://pyyaml.org/wiki/PyYAML) page.)
* Enter the the Absolute Path of the CloudTSA project till `iter8/cloudtsa` folder under `config['project_home']` in `iter8/cloudtsa/config/config.json`

<a name="initialization"></a>
## Initialize
### Open two terminals
We will refer to them as terminals 1 and 2.

### Port forward Grafana service
In terminal 1, run the following command.
```
kubectl -n istio-system port-forward $(kubectl -n istio-system get pod -l app=grafana -o jsonpath='{.items[0].metadata.name}') 3000:3000 &
```
**The above command** port forwards the Grafana service (installed as an Istio addon) to your localhost and local port *3000*. More information on using Istio and Grafana together is available
[here](https://istio.io/docs/tasks/telemetry/using-istio-dashboard/).

### Install and configure demo
In terminal 1, navigate to the correct folder
and run the following command.
```
cd iter8/iter8/cloudtsa/demo
python3 democonfigure.py -dc democonfig.json
```

**The above command** deploys the sample application and the CloudTSA service in your Kubernetes cluster, extracts the web address at which HTTP queries can be sent to the sample application,
reconfigures Prometheus in your demo environment so that it can pull the insights generated by the CloudTSA service, and imports the CloudTSA dashboard into your Grafana service. To view the CloudTSA dashboard, go to `Manage` under `Dashboards` on your Grafana service and click on `cloudtsa demo`.

### Start the load generator
In terminal 2, navigate to the correct folder
and run the following command.
```
cd iter8/iter8/cloudtsa/demo
python3 ping.py -dc democonfig.json -t ../config/topology.json -p 20
```

**The above command** queries each service in the sample application at random at a total
frequency of ~20 queries / sec.

### Initialize the sample application and start the CloudTSA service
In terminal 1, run the following command.
```
python3 demoinitialize.py -dc democonfig.json
```

**The above command** initializes the sample application by setting the mean processing delay of all its services to 0.1 sec and their failure rates (i.e., the probability of them aborting with a 500 HTTP status code) to 0.0. It also starts the CloudTSA service.

<a name="run"></a>
## Run the demos

<a name="predict"></a>
### Demo 1: Predictively monitor gradual drifts in latency
This demo illustrates how the predictive monitoring capabilities of CloudTSA can be combined with the latency metric of a service in order to detect significant increases in service latencies *before* their occurrence. **Start this demo by running**:
```
python3 demorun.py -dc democonfig.json -s gradual_latency
```

**In your CloudTSA dashboard in Grafana,** navigate to the two charts titled *Latency for Svc0* and *CloudTSA (latency) Alerts for Svc0*; you will see these charts getting updated as in the following animation over a period of *8 min*.

<p align="center">
  <img src="https://raw.githubusercontent.com/istio-ecosystem/iter8-docs/master/cloudtsa/gif/gradual_latency.gif">
</p>

Service `svc0` experiences a gradual increase in mean latency from ~ 0.1 sec to ~ 8.0 sec which you can see on the chart on the left. CloudTSA learns this trend and creates two types of alerts for `svc0` which you can see on the chart on the right.

  1. A 'reactive' alert (pink curve) *after* the mean latency value violates a preset threshold.

  2. A 'predictive' alert (blue curve) *before* the mean latency value violates a preset threshold. CloudTSA uses the Holt-Winters triple exponential smoothing algorithm to infer the increasing trend in latency and *predicts* that latency is likely to violate a preset threshold.

### Demo 2 (two parts): Detect abrupt increases in latency
This demo has two parts which illustrate how change detection capabilities of CloudTSA can be combined with the latency metric of a service in order to detect abrupt increases in service latencies. The change detection is based on the CUSUM algorithm which is statistically more robust than a direct
comparison of mean latency to a preset threshold.

#### Part 1
**Start part 1 of this demo by running:**
```
python3 demorun.py -dc democonfig.json -s abrupt_latency_part1
```

**In your CloudTSA dashboard in Grafana,** navigate to the two charts titled *Latency for Svc1* and *CloudTSA (latency) Alerts for Svc1*; you will see these charts getting updated as in the following animation over a period of 4 min.

<p align="center">
  <img src="https://raw.githubusercontent.com/istio-ecosystem/iter8-docs/master/cloudtsa/gif/abrupt_latency_part1.gif">
</p>

The mean processing delay of `svc1` is abruptly increased from 0.1 sec to 5.0 sec as seen on the chart on the left. The change detection algorithm observes this abrupt change in behavior and fires an alarm as seen on the chart on the right.

#### Part 2
**Start this demo by running**:
```
python3 demorun.py -dc democonfig.json -s abrupt_latency_part2
```
**In your CloudTSA dashboard in Grafana,** you will see the charts from part 1 getting updated as in the following animation over a period of 4 min.

<p align="center">
  <img src="https://raw.githubusercontent.com/istio-ecosystem/iter8-docs/master/cloudtsa/gif/abrupt_latency_part2.gif">
</p>

In this part of the demo, the mean processing delay of `svc1` is increased evey further from 5.0 sec to 10.0 sec. The change detection algorithm observes this second abrupt change in the service latency and fires another alarm. The service latency has now breached a preset threshold which triggers a `thresholdpolicy` alarm as well.

<a name="abrupterror"></a>
### Demo 3: Detect abrupt increase in errors
This demo illustrates how the change detection capabilities of CloudTSA can be combined with the error count or error rate metric of a service in order to detect abrupt increases in errors. **Start this demo by running**:
```
python3 demorun.py -dc democonfig.json -s abrupt_errors
```
**In your CloudTSA dashboard in Grafana,** navigate to the two charts titled *Error Count for Svc2* and *CloudTSA (Errorcount) Alerts for Svc2*. The error rate related charts are titled *Error Rate for Svc2* and *CloudTSA (Error Rate) Alerts for Svc2*; you will see these charts getting updated as in the following animation over a period of 5-7 min.

<p align="center">
  <img src="https://raw.githubusercontent.com/istio-ecosystem/iter8-docs/master/cloudtsa/gif/abrupt_error_count.gif">
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/istio-ecosystem/iter8-docs/master/cloudtsa/gif/abrupt_error_rate.gif">
</p>

This demo shows the alerts that can be generated by CloudTSA when there is an abrupt increase in the errors generated by a service. The failure rate of the service `svc2` (i.e., the probability of the service aborting with a 500 HTTP status code) is abruptly increased from ~0.0 to ~0.2 . This increases both the error rate and error counts for `svc2`. The change detection algorithm observes both these abrupt changes in behavior and fires alarms. The increased error rates and counts also breach the preset thresholds of the `thresholdpolicy` detector which fires alarms as well.

<a name="peak"></a>
### Demo 4: Detect peaks in load
This demo illustrates how the peak detection capabilities of CloudTSA can be combined with the load metric of a service in order to detect peaks in load. **Start this demo by running**:
```
python3 demorun.py -dc democonfig.json -s peak
```

**The above command** creates fluctuations in the rate at which service `svc3`
is queried thereby creating peaks in its load metric.

**In your CloudTSA dashboard in Grafana,** navigate to the two charts titled *Total Load on Svc3* and *CloudTSA (Load) Alerts for Svc3*; you will see these charts getting updated as in the following animation over a period of 4 min.

<p align="center">
  <img src="https://raw.githubusercontent.com/istio-ecosystem/iter8-docs/master/cloudtsa/gif/peak.gif">
</p>

On the left, you can visualize the peaks in the load of service `svc3`. On the right, you see the corresponding alarms generated by CloudTSA for these peaks.
